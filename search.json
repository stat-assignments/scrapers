[{"path":"https://stat-assignments.github.io/scrapers/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 scrapers authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://stat-assignments.github.io/scrapers/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Heike Hofmann. Author, maintainer, copyright holder. Susan Vanderplas. Author.","code":""},{"path":"https://stat-assignments.github.io/scrapers/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hofmann H, Vanderplas S (2025). scrapers: Scrapers setting updating data stat-assigments. R package version 0.1.0, https://stat-assignments.github.io/scrapers/, https://github.com/stat-assignments/scrapers.","code":"@Manual{,   title = {scrapers: Scrapers for setting up and updating data in stat-assigments},   author = {Heike Hofmann and Susan Vanderplas},   year = {2025},   note = {R package version 0.1.0, https://stat-assignments.github.io/scrapers/},   url = {https://github.com/stat-assignments/scrapers}, }"},{"path":"https://stat-assignments.github.io/scrapers/index.html","id":"scrapers","dir":"","previous_headings":"","what":"Scrapers for setting up and updating data in stat-assigments","title":"Scrapers for setting up and updating data in stat-assigments","text":"goal scrapers …","code":""},{"path":"https://stat-assignments.github.io/scrapers/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Scrapers for setting up and updating data in stat-assigments","text":"can install development version scrapers like :","code":"remotes::install_github(\"stat-assignments/scraper\")"},{"path":"https://stat-assignments.github.io/scrapers/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Scrapers for setting up and updating data in stat-assigments","text":"basic example shows solve common problem:","code":"library(scrapers) library(tidyverse, quietly = TRUE) #> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── #> ✔ dplyr     1.1.4     ✔ readr     2.1.5 #> ✔ forcats   1.0.0     ✔ stringr   1.5.1 #> ✔ ggplot2   3.5.1     ✔ tibble    3.2.1 #> ✔ lubridate 1.9.3     ✔ tidyr     1.3.1 #> ✔ purrr     1.0.4      #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() #> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors ## basic example code  eq <- get_earthquakes(lubridate::today()-30, lubridate::today()) eq %>% ggplot(aes(x = longitude, y = latitude)) + geom_point()"},{"path":"https://stat-assignments.github.io/scrapers/reference/get_earthquakes.html","id":null,"dir":"Reference","previous_headings":"","what":"Get earthquake information from USGS — get_earthquakes","title":"Get earthquake information from USGS — get_earthquakes","text":"Downloads records earth quakes USGS Earthquake Catalog","code":""},{"path":"https://stat-assignments.github.io/scrapers/reference/get_earthquakes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get earthquake information from USGS — get_earthquakes","text":"","code":"get_earthquakes(   start_time = today() - 30,   end_time = NULL,   min_magnitude = NULL,   base_url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\" )"},{"path":"https://stat-assignments.github.io/scrapers/reference/get_earthquakes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get earthquake information from USGS — get_earthquakes","text":"start_time character string specifying start date records form 'yyyy-mm-dd' end_time character string specifying end date records form 'yyyy-mm-dd' min_magnitude numeric quantity specifying minimum magnitude considered record base_url base url GET request","code":""},{"path":"https://stat-assignments.github.io/scrapers/reference/get_earthquakes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get earthquake information from USGS — get_earthquakes","text":"data frame earth quake records. Detailed information variables can found part [USGS ComCat Documentation](https://earthquake.usgs.gov/data/comcat/index.php). default, data last 30 days requested archive. similar data USGS provides `Earthquakes` past 30 days spreadsheet/csv feed https://earthquake.usgs.gov/earthquakes/feed/v1.0/csv.php","code":""},{"path":"https://stat-assignments.github.io/scrapers/reference/get_earthquakes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get earthquake information from USGS — get_earthquakes","text":"","code":"# example code library(lubridate) #>  #> Attaching package: ‘lubridate’ #> The following objects are masked from ‘package:base’: #>  #>     date, intersect, setdiff, union todays <- get_earthquakes(start_time = today()-1, end_time = today()) # all documented earthquakes with a magnitude of at least 9 on the Richter scale nines <-  get_earthquakes(start_time = \"1800-01-01\", end_time = today(), min_magnitude=9)"},{"path":"https://stat-assignments.github.io/scrapers/reference/get_user_comments.html","id":null,"dir":"Reference","previous_headings":"","what":"Get user content from reddit — get_user_comments","title":"Get user content from reddit — get_user_comments","text":"Download individual user's content reddit","code":""},{"path":"https://stat-assignments.github.io/scrapers/reference/get_user_comments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get user content from reddit — get_user_comments","text":"","code":"get_user_comments(   user_name,   limit = 10L,   after = NULL,   base_url = \"https://www.reddit.com/\" )"},{"path":"https://stat-assignments.github.io/scrapers/reference/get_user_comments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get user content from reddit — get_user_comments","text":"user_name character string individual reddit user limit integer value 1 100 character string specifying location list user comments. specified, comments location returned (found). base_url base url GET request","code":""},{"path":"https://stat-assignments.github.io/scrapers/reference/get_user_comments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get user content from reddit — get_user_comments","text":"list containing named items: `data`, ``, `request`. `data` data frame reddit comments user. `` character value hashed location last comment included returned items. value can used starting point next batch responses. `request` exact string results returned.","code":""},{"path":"https://stat-assignments.github.io/scrapers/reference/get_user_comments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get user content from reddit — get_user_comments","text":"","code":"# example code sprog2 <- get_user_comments(user_name=\"poem_for_your_sprog\", limit=2) #> Error in get_user_comments(user_name = \"poem_for_your_sprog\", limit = 2): Error in req_perform(req) : HTTP 403 Forbidden. sprog_next2 <- get_user_comments(user_name=\"poem_for_your_sprog\", limit=2, after=sprog2$after) #> Error: object 'sprog2' not found sprog4 <- get_user_comments(user_name=\"poem_for_your_sprog\", limit=4) #> Error in get_user_comments(user_name = \"poem_for_your_sprog\", limit = 4): Error in req_perform(req) : HTTP 403 Forbidden."}]
